{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from concurrent.futures import ThreadPoolExecutor  \n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.firefox.service import Service\n",
    "# from selenium.webdriver.firefox.options import Options\n",
    "# from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# import time\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# from datetime import datetime\n",
    "\n",
    "# # üîπ Function to Start Firefox Browser\n",
    "# def start_browser(link, dfolder, geko_path, window_size='1500,1080'):\n",
    "#     os.makedirs(dfolder, exist_ok=True)\n",
    "#     options = Options()\n",
    "#     options.add_argument('--start-maximized')\n",
    "#     options.set_preference('privacy.trackingprotection.enabled', True)\n",
    "#     service = Service(geko_path)\n",
    "#     browser = webdriver.Firefox(service=service, options=options)\n",
    "    \n",
    "#     width, height = map(int, window_size.split(','))\n",
    "#     browser.set_window_size(width, height)\n",
    "    \n",
    "#     browser.get(link)\n",
    "#     time.sleep(3)  # Let page load\n",
    "    \n",
    "#     return browser\n",
    "\n",
    "# # üîπ Function to Search, Scroll & Scrape Hotels\n",
    "# def search_and_scrape(browser, city, year, month, month_text, arrival_day, departure_day, filename):\n",
    "#     try:\n",
    "#         print(f\"Searching for {city} ({year}-{month}-{arrival_day} to {year}-{month}-{departure_day})\")\n",
    "\n",
    "#         # Click search bar and enter city\n",
    "#         WebDriverWait(browser, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\":rh:\"]'))).click()\n",
    "#         time.sleep(1)\n",
    "#         search_box = WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\":rh:\"]')))\n",
    "#         search_box.send_keys(city)\n",
    "#         time.sleep(1)\n",
    "#         browser.find_element(By.XPATH, '//*[@class=\"ebbedaf8ac ab26a5d2bd e33c97ff6b\"]').click()\n",
    "#         time.sleep(2)\n",
    "\n",
    "#         # Select correct month and year\n",
    "#         target_date = month_text + ' ' + year\n",
    "#         while browser.find_element(By.XPATH, '//h3[contains(@class, \"e1eebb6a1e ee7ec6b631\")]').text.strip() != target_date:\n",
    "#             browser.find_element(By.XPATH, '//*[@class=\"a83ed08757 c21c56c305 f38b6daa18 d691166b09 f671049264 f4552b6561 dc72a8413c f073249358\"]').click()\n",
    "#             time.sleep(1)\n",
    "\n",
    "#         # Select arrival and departure dates\n",
    "#         dates = browser.find_elements(By.XPATH, '//table[@class=\"eb03f3f27f\"]//td[@class=\"b80d5adb18\"]//span[@class=\"cf06f772fa ef091eb985\"]')\n",
    "#         for date in dates:\n",
    "#             if date.get_attribute(\"data-date\") == f\"{year}-{month}-{arrival_day}\":\n",
    "#                 date.click()\n",
    "#             if date.get_attribute(\"data-date\") == f\"{year}-{month}-{departure_day}\":\n",
    "#                 date.click()\n",
    "#                 break\n",
    "#         time.sleep(2)\n",
    "\n",
    "#         # Click search button\n",
    "#         browser.find_element(By.XPATH, '//button[@class=\"a83ed08757 c21c56c305 a4c1805887 f671049264 a2abacf76b c082d89982 cceeb8986b b9fd3c6b3c\"]').click()\n",
    "#         time.sleep(2)\n",
    "\n",
    "#         # üîπ Scroll and load all results\n",
    "#         print(f\"Scrolling and clicking 'See More' for {city}...\")\n",
    "#         i = 0\n",
    "#         while True:\n",
    "#             try:\n",
    "#                 total_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "#                 browser.execute_script(f\"window.scrollTo(0, {total_height});\")\n",
    "#                 time.sleep(2)  # Allow content to load\n",
    "\n",
    "#                 load_more_button = WebDriverWait(browser, 5).until(\n",
    "#                     EC.element_to_be_clickable((By.XPATH, '//button[@class=\"a83ed08757 c21c56c305 bf0537ecb5 f671049264 af7297d90d c0e0affd09\"]'))\n",
    "#                 )\n",
    "#                 load_more_button.click()\n",
    "#                 i += 1\n",
    "#             except (NoSuchElementException, TimeoutException):\n",
    "#                 break\n",
    "        \n",
    "#         print(f'üîπ The \"See More\" button was clicked {i} times')\n",
    "\n",
    "#         # **FIXED: Ensure browser stays open for scraping**\n",
    "#         print(f\"Scraping hotels for {city}...\")\n",
    "#         hotel_list_data = scrape_hotel_list_page_from_selenium(browser)\n",
    "        \n",
    "#         # üîπ Handle Empty Scraping Result (Retry Once)\n",
    "#         if not hotel_list_data:\n",
    "#             print(\"‚ö† No hotels found. Retrying...\")\n",
    "#             time.sleep(3)  # Allow page to fully load\n",
    "#             hotel_list_data = scrape_hotel_list_page_from_selenium(browser)\n",
    "\n",
    "#         if hotel_list_data:\n",
    "#             df = pd.DataFrame(hotel_list_data, columns=['Name', 'Price', 'Rating', 'Detail Link'])\n",
    "#             df.to_csv(filename, index=False)\n",
    "#             print(f\"‚úÖ Hotel data saved to {filename}\")\n",
    "#         else:\n",
    "#             print(\"‚ùå Failed to scrape any hotels.\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Error during search and scrape: {e}\")\n",
    "\n",
    "#     finally:\n",
    "#         print(f\"üõë Closing browser for {city}\")\n",
    "#         browser.quit()\n",
    "\n",
    "# # üîπ Function to Scrape Hotel Data\n",
    "# def scrape_hotel_list_page_from_selenium(browser):\n",
    "#     page_source = browser.page_source\n",
    "#     soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    \n",
    "#     hotel_data = []\n",
    "#     hotels = soup.find_all('div', {'data-testid': 'property-card'})\n",
    "    \n",
    "#     for hotel in hotels:\n",
    "#         name = hotel.find('div', {'data-testid': 'title'}).get_text(strip=True) if hotel.find('div', {'data-testid': 'title'}) else \"NA\"\n",
    "#         price = hotel.find('span', {'class': 'f6431b446c fbfd7c1165 e84eb96b1f'}).get_text(strip=True) if hotel.find('span', {'class': 'f6431b446c fbfd7c1165 e84eb96b1f'}) else \"NA\"\n",
    "#         rating_container = hotel.find('div', {'data-testid': 'review-score'})\n",
    "#         rating = rating_container.find('div').get_text(strip=True) if rating_container else \"NA\"\n",
    "#         detail_link = hotel.find('a', {'data-testid': 'title-link'})['href'] if hotel.find('a', {'data-testid': 'title-link'}) else None \n",
    "#         if detail_link:\n",
    "#             detail_link = f\"https://www.booking.com{detail_link}\"\n",
    "        \n",
    "#         hotel_data.append([name, price, rating, detail_link])\n",
    "    \n",
    "#     return hotel_data\n",
    "\n",
    "# # üîπ Function to Handle Multiple Browsers\n",
    "# def scrape_with_browser(browser_id):\n",
    "#     dfolder = './downloads'\n",
    "#     geko_path = ''\n",
    "#     link = 'https://www.booking.com/index.es.html'\n",
    "    \n",
    "#     browser = start_browser(link, dfolder, geko_path)\n",
    "\n",
    "#     locations = [\n",
    "#         (\"Barcelona\", \"2025\", \"03\", \"marzo\", \"01\", \"07\", \"hotels_barcelona_MWC.csv\"),\n",
    "#         (\"Madrid\", \"2025\", \"03\", \"marzo\", \"01\", \"07\", \"hotels_madrid_mar_MWC.csv\"),\n",
    "#         (\"Barcelona\", \"2025\", \"03\", \"marzo\", \"22\", \"28\", \"hotels_barcelona_after_MWC.csv\"),\n",
    "#         (\"Madrid\", \"2025\", \"03\", \"marzo\", \"22\", \"28\", \"hotels_madrid_after_MWC.csv\")\n",
    "#     ]\n",
    "\n",
    "#     city, year, month, month_text, arrival_day, departure_day, filename = locations[browser_id]\n",
    "#     search_and_scrape(browser, city, year, month, month_text, arrival_day, departure_day, filename)\n",
    "\n",
    "# # üîπ Run 4 Browsers in Parallel\n",
    "# if __name__ == \"__main__\":\n",
    "#     num_browsers = 4\n",
    "#     with ThreadPoolExecutor(max_workers=num_browsers) as executor:\n",
    "#         executor.map(scrape_with_browser, range(num_browsers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for Barcelona (2025-03-22 to 2025-03-28)\n",
      "Searching for Barcelona (2025-03-01 to 2025-03-07)\n",
      "Searching for Madrid (2025-03-01 to 2025-03-07)\n",
      "Searching for Madrid (2025-03-22 to 2025-03-28)\n",
      "Scrolling and clicking 'See More' for Barcelona...\n",
      "Scrolling and clicking 'See More' for Barcelona...\n",
      "Scrolling and clicking 'See More' for Madrid...\n",
      "Scrolling and clicking 'See More' for Madrid...\n",
      "üîπ The \"See More\" button was clicked 0 times\n",
      "Scraping hotels for Barcelona...\n",
      "üîπ The \"See More\" button was clicked 0 times\n",
      "Scraping hotels for Madrid...\n",
      "‚úÖ Hotel data saved to hotels_barcelona_after_MWC.csv\n",
      "üõë Closing browser for Barcelona\n",
      "‚úÖ Hotel data saved to hotels_madrid_MWC.csv\n",
      "üõë Closing browser for Madrid\n",
      "üîπ The \"See More\" button was clicked 37 times\n",
      "Scraping hotels for Madrid...\n",
      "üîπ The \"See More\" button was clicked 37 times\n",
      "Scraping hotels for Barcelona...\n",
      "Error scraping details from https://www.booking.com/hotel/es/spacious-and-cozy-caribbean-boat-in-barcelona.es.html?label=gen173nr-1FCAEoggI46AdIClgEaEaIAQGYAQq4AQfIAQ_YAQHoAQH4AQKIAgGoAgO4Ao2l77wGwAIB0gIkNzNhMmIyN2QtMDg4OC00MGZjLThlZTEtYjNkNzAwMjMxZWVl2AIF4AIB&aid=304142&ucfs=1&arphpl=1&checkin=2025-03-01&checkout=2025-03-07&dest_id=-372490&dest_type=city&group_adults=2&req_adults=2&no_rooms=1&group_children=0&req_children=0&hpos=23&hapos=908&sr_order=popularity&srpvid=db6088cd2c8903c4&srepoch=1738265345&all_sr_blocks=775886901_376014206_2_0_0&highlighted_blocks=775886901_376014206_2_0_0&matching_block_id=775886901_376014206_2_0_0&sr_pri_blocks=775886901_376014206_2_0_0__104270&from=searchresults: HTTPSConnectionPool(host='www.booking.com', port=443): Read timed out. (read timeout=10)\n",
      "Error scraping details from https://www.booking.com/hotel/es/bnbholder-flowery-plaza-espana.es.html?label=gen173nr-1FCAEoggI46AdIClgEaEaIAQGYAQq4AQfIAQ_YAQHoAQH4AQKIAgGoAgO4Ao6l77wGwAIB0gIkMTAxOWJlZmItZWMzMy00ZTQ2LWEzZDktODRkOGJkOWIyMzcy2AIF4AIB&aid=304142&ucfs=1&arphpl=1&checkin=2025-03-22&checkout=2025-03-28&dest_id=176&dest_type=district&group_adults=2&req_adults=2&no_rooms=1&group_children=0&req_children=0&hpos=13&hapos=921&sr_order=popularity&srpvid=7c9c88cdf74e036d&srepoch=1738265339&all_sr_blocks=516577202_383725037_4_0_0&highlighted_blocks=516577202_383725037_4_0_0&matching_block_id=516577202_383725037_4_0_0&sr_pri_blocks=516577202_383725037_4_0_0__144928&from=searchresults: HTTPSConnectionPool(host='www.booking.com', port=443): Read timed out. (read timeout=10)\n",
      "Error scraping details from https://www.booking.com/hotel/es/bright-and-modern-3bedroom-in-las-ramblas-3-1b.es.html?label=gen173nr-1FCAEoggI46AdIClgEaEaIAQGYAQq4AQfIAQ_YAQHoAQH4AQKIAgGoAgO4Ao2l77wGwAIB0gIkNzNhMmIyN2QtMDg4OC00MGZjLThlZTEtYjNkNzAwMjMxZWVl2AIF4AIB&aid=304142&ucfs=1&arphpl=1&checkin=2025-03-01&checkout=2025-03-07&dest_id=-372490&dest_type=city&group_adults=2&req_adults=2&no_rooms=1&group_children=0&req_children=0&hpos=7&hapos=917&sr_order=popularity&srpvid=db6088cd2c8903c4&srepoch=1738265348&all_sr_blocks=874023302_399861706_4_0_0&highlighted_blocks=874023302_399861706_4_0_0&matching_block_id=874023302_399861706_4_0_0&sr_pri_blocks=874023302_399861706_4_0_0__317006&from=searchresults: HTTPSConnectionPool(host='www.booking.com', port=443): Read timed out. (read timeout=10)\n",
      "Error scraping details from https://www.booking.com/hotel/es/apartamento-plaza-colon-colon-ii.es.html?label=gen173nr-1FCAEoggI46AdIClgEaEaIAQGYAQq4AQfIAQ_YAQHoAQH4AQKIAgGoAgO4Ao6l77wGwAIB0gIkMTAxOWJlZmItZWMzMy00ZTQ2LWEzZDktODRkOGJkOWIyMzcy2AIF4AIB&aid=304142&ucfs=1&arphpl=1&checkin=2025-03-22&checkout=2025-03-28&dest_id=176&dest_type=district&group_adults=2&req_adults=2&no_rooms=1&group_children=0&req_children=0&hpos=21&hapos=929&sr_order=popularity&srpvid=7c9c88cdf74e036d&srepoch=1738265339&all_sr_blocks=1139624702_393498777_0_0_0&highlighted_blocks=1139624702_393498777_0_0_0&matching_block_id=1139624702_393498777_0_0_0&sr_pri_blocks=1139624702_393498777_0_0_0__143451&from=searchresults: HTTPSConnectionPool(host='www.booking.com', port=443): Read timed out. (read timeout=10)\n",
      "Error scraping details from https://www.booking.com/hotel/es/bright-and-modern-2bedroom-in-las-ramblas-2-1a.es.html?label=gen173nr-1FCAEoggI46AdIClgEaEaIAQGYAQq4AQfIAQ_YAQHoAQH4AQKIAgGoAgO4Ao2l77wGwAIB0gIkNzNhMmIyN2QtMDg4OC00MGZjLThlZTEtYjNkNzAwMjMxZWVl2AIF4AIB&aid=304142&ucfs=1&arphpl=1&checkin=2025-03-01&checkout=2025-03-07&dest_id=-372490&dest_type=city&group_adults=2&req_adults=2&no_rooms=1&group_children=0&req_children=0&hpos=9&hapos=919&sr_order=popularity&srpvid=db6088cd2c8903c4&srepoch=1738265348&all_sr_blocks=874023702_399861654_4_0_0&highlighted_blocks=874023702_399861654_4_0_0&matching_block_id=874023702_399861654_4_0_0&sr_pri_blocks=874023702_399861654_4_0_0__285882&from=searchresults: HTTPSConnectionPool(host='www.booking.com', port=443): Read timed out. (read timeout=10)\n",
      "Error scraping details from https://www.booking.com/hotel/es/bright-and-modern-4bedroom-with-terrace-in-las-ramblas-p1.es.html?label=gen173nr-1FCAEoggI46AdIClgEaEaIAQGYAQq4AQfIAQ_YAQHoAQH4AQKIAgGoAgO4Ao2l77wGwAIB0gIkNzNhMmIyN2QtMDg4OC00MGZjLThlZTEtYjNkNzAwMjMxZWVl2AIF4AIB&aid=304142&ucfs=1&arphpl=1&checkin=2025-03-01&checkout=2025-03-07&dest_id=-372490&dest_type=city&group_adults=2&req_adults=2&no_rooms=1&group_children=0&req_children=0&hpos=11&hapos=921&sr_order=popularity&srpvid=db6088cd2c8903c4&srepoch=1738265348&all_sr_blocks=874022702_399861628_6_0_0&highlighted_blocks=874022702_399861628_6_0_0&matching_block_id=874022702_399861628_6_0_0&sr_pri_blocks=874022702_399861628_6_0_0__496858&from=searchresults: HTTPSConnectionPool(host='www.booking.com', port=443): Read timed out. (read timeout=10)\n",
      "Error scraping details from https://www.booking.com/hotel/es/bnbholder-art-loft-la-latina.es.html?label=gen173nr-1FCAEoggI46AdIClgEaEaIAQGYAQq4AQfIAQ_YAQHoAQH4AQKIAgGoAgO4Ao6l77wGwAIB0gIkMTAxOWJlZmItZWMzMy00ZTQ2LWEzZDktODRkOGJkOWIyMzcy2AIF4AIB&aid=304142&ucfs=1&arphpl=1&checkin=2025-03-22&checkout=2025-03-28&dest_id=176&dest_type=district&group_adults=2&req_adults=2&no_rooms=1&group_children=0&req_children=0&hpos=7&hapos=940&sr_order=popularity&srpvid=7c9c88cdf74e036d&srepoch=1738265342&all_sr_blocks=798380501_340034857_6_0_0&highlighted_blocks=798380501_340034857_6_0_0&matching_block_id=798380501_340034857_6_0_0&sr_pri_blocks=798380501_340034857_6_0_0__226588&from=searchresults: HTTPSConnectionPool(host='www.booking.com', port=443): Read timed out. (read timeout=10)\n",
      "Error scraping details from https://www.booking.com/hotel/es/canela-homes-barcelona-bruc.es.html?label=gen173nr-1FCAEoggI46AdIClgEaEaIAQGYAQq4AQfIAQ_YAQHoAQH4AQKIAgGoAgO4Ao2l77wGwAIB0gIkNzNhMmIyN2QtMDg4OC00MGZjLThlZTEtYjNkNzAwMjMxZWVl2AIF4AIB&aid=304142&ucfs=1&arphpl=1&checkin=2025-03-01&checkout=2025-03-07&dest_id=-372490&dest_type=city&group_adults=2&req_adults=2&no_rooms=1&group_children=0&req_children=0&hpos=17&hapos=927&sr_order=popularity&srpvid=db6088cd2c8903c4&srepoch=1738265348&all_sr_blocks=1224678001_394574800_2_0_0&highlighted_blocks=1224678001_394574800_2_0_0&matching_block_id=1224678001_394574800_2_0_0&sr_pri_blocks=1224678001_394574800_2_0_0__300125&from=searchresults: HTTPSConnectionPool(host='www.booking.com', port=443): Read timed out. (read timeout=10)\n",
      "‚úÖ Hotel data saved to hotels_barcelona_MWC.csv\n",
      "üõë Closing browser for Barcelona\n",
      "‚úÖ Hotel data saved to hotels_madrid_after_MWC.csv\n",
      "üõë Closing browser for Madrid\n"
     ]
    }
   ],
   "source": [
    " from concurrent.futures import ThreadPoolExecutor  \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "# üîπ Function to Start Firefox Browser\n",
    "def start_browser(link, dfolder, geko_path, window_size='1500,1080'):\n",
    "    os.makedirs(dfolder, exist_ok=True)\n",
    "    options = Options()\n",
    "    options.add_argument('--start-maximized')\n",
    "    options.set_preference('privacy.trackingprotection.enabled', True)\n",
    "    service = Service(geko_path)\n",
    "    browser = webdriver.Firefox(service=service, options=options)\n",
    "    \n",
    "    width, height = map(int, window_size.split(','))\n",
    "    browser.set_window_size(width, height)\n",
    "    \n",
    "    browser.get(link)\n",
    "    time.sleep(3)  # Let page load\n",
    "    \n",
    "    return browser\n",
    "\n",
    "# üîπ Function to Search, Scroll & Scrape Hotels\n",
    "def search_and_scrape(browser, city, year, month, month_text, arrival_day, departure_day, filename):\n",
    "    try:\n",
    "        print(f\"Searching for {city} ({year}-{month}-{arrival_day} to {year}-{month}-{departure_day})\")\n",
    "\n",
    "        # Click search bar and enter city\n",
    "        WebDriverWait(browser, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\":rh:\"]'))).click()\n",
    "        time.sleep(1)\n",
    "        search_box = WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\":rh:\"]')))\n",
    "        search_box.send_keys(city)\n",
    "        time.sleep(1)\n",
    "        browser.find_element(By.XPATH, '//*[@class=\"ebbedaf8ac ab26a5d2bd e33c97ff6b\"]').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Select correct month and year\n",
    "        target_date = month_text + ' ' + year\n",
    "        while browser.find_element(By.XPATH, '//h3[contains(@class, \"e1eebb6a1e ee7ec6b631\")]').text.strip() != target_date:\n",
    "            browser.find_element(By.XPATH, '//*[@class=\"a83ed08757 c21c56c305 f38b6daa18 d691166b09 f671049264 f4552b6561 dc72a8413c f073249358\"]').click()\n",
    "            time.sleep(1)\n",
    "\n",
    "        # Select arrival and departure dates\n",
    "        dates = browser.find_elements(By.XPATH, '//table[@class=\"eb03f3f27f\"]//td[@class=\"b80d5adb18\"]//span[@class=\"cf06f772fa ef091eb985\"]')\n",
    "        for date in dates:\n",
    "            if date.get_attribute(\"data-date\") == f\"{year}-{month}-{arrival_day}\":\n",
    "                date.click()\n",
    "            if date.get_attribute(\"data-date\") == f\"{year}-{month}-{departure_day}\":\n",
    "                date.click()\n",
    "                break\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Click search button\n",
    "        browser.find_element(By.XPATH, '//button[@class=\"a83ed08757 c21c56c305 a4c1805887 f671049264 a2abacf76b c082d89982 cceeb8986b b9fd3c6b3c\"]').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        # üîπ Scroll and load all results\n",
    "        print(f\"Scrolling and clicking 'See More' for {city}...\")\n",
    "        i = 0\n",
    "        while True:\n",
    "            try:\n",
    "                total_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "                browser.execute_script(f\"window.scrollTo(0, {total_height});\")\n",
    "                time.sleep(2)  # Allow content to load\n",
    "\n",
    "                load_more_button = WebDriverWait(browser, 5).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, '//button[@class=\"a83ed08757 c21c56c305 bf0537ecb5 f671049264 af7297d90d c0e0affd09\"]'))\n",
    "                )\n",
    "                load_more_button.click()\n",
    "                i += 1\n",
    "            except (NoSuchElementException, TimeoutException):\n",
    "                break\n",
    "        \n",
    "        print(f'üîπ The \"See More\" button was clicked {i} times')\n",
    "\n",
    "        # Scrape hotels\n",
    "        print(f\"Scraping hotels for {city}...\")\n",
    "        hotel_list_data = scrape_hotel_list_page_from_selenium(browser)\n",
    "\n",
    "        # **Extract descriptions**\n",
    "        descriptions = []\n",
    "        for hotel in hotel_list_data:\n",
    "            if hotel[3] != \"NA\":\n",
    "                descriptions.append(scrape_hotel_detail_page(hotel[3]))  # Append description\n",
    "            else:\n",
    "                descriptions.append(\"NA\")  # No link, add \"NA\" to description\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        if hotel_list_data:\n",
    "            df = pd.DataFrame(hotel_list_data, columns=['Name', 'Price', 'Rating', 'Detail Link'])\n",
    "            df['Description'] = descriptions  # Add descriptions column\n",
    "            df.to_csv(filename, index=False)\n",
    "            print(f\"‚úÖ Hotel data saved to {filename}\")\n",
    "        else:\n",
    "            print(\"‚ùå No hotels found.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during search and scrape: {e}\")\n",
    "\n",
    "    finally:\n",
    "        print(f\"üõë Closing browser for {city}\")\n",
    "        browser.quit()\n",
    "\n",
    "# üîπ Function to Scrape Hotel List\n",
    "def scrape_hotel_list_page_from_selenium(browser):\n",
    "    soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "    \n",
    "    hotel_data = []\n",
    "    hotels = soup.find_all('div', {'data-testid': 'property-card'})\n",
    "    \n",
    "    for hotel in hotels:\n",
    "        name = hotel.find('div', {'data-testid': 'title'}).get_text(strip=True) if hotel.find('div', {'data-testid': 'title'}) else \"NA\"\n",
    "        price = hotel.find('span', {'class': 'f6431b446c fbfd7c1165 e84eb96b1f'}).get_text(strip=True) if hotel.find('span', {'class': 'f6431b446c fbfd7c1165 e84eb96b1f'}) else \"NA\"\n",
    "        rating_container = hotel.find('div', {'data-testid': 'review-score'})\n",
    "        rating = rating_container.find('div').get_text(strip=True) if rating_container else \"NA\"\n",
    "        detail_link = hotel.find('a', {'data-testid': 'title-link'})['href'] if hotel.find('a', {'data-testid': 'title-link'}) else None\n",
    "        detail_link = detail_link if detail_link else \"NA\"\n",
    "        \n",
    "        hotel_data.append([name, price, rating, detail_link])\n",
    "    \n",
    "    return hotel_data\n",
    "\n",
    "# üîπ Function to Scrape Hotel Description\n",
    "def scrape_hotel_detail_page(detail_url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(detail_url, headers=headers, timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            return \"Failed to load page\"\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # **Try multiple possible description locations**\n",
    "        description = soup.find('p', {'data-testid': 'property-description'})\n",
    "        if not description:\n",
    "            description = soup.find('div', {'class': 'a53cbfa6de b3efd73f69'})\n",
    "        if not description:\n",
    "            description = soup.find('span', {'class': 'e84eb96b1f'})\n",
    "        \n",
    "        return description.get_text(strip=True) if description else \"NA\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping details from {detail_url}: {e}\")\n",
    "        return \"Error\"\n",
    "def scrape_with_browser(browser_id):\n",
    "    dfolder = './downloads'\n",
    "    geko_path = ''  # Add the correct GeckoDriver path\n",
    "    link = 'https://www.booking.com/index.es.html'\n",
    "    \n",
    "    browser = start_browser(link, dfolder, geko_path)\n",
    "\n",
    "    locations = [\n",
    "        (\"Barcelona\", \"2025\", \"03\", \"marzo\", \"01\", \"07\", \"hotels_barcelona_MWC.csv\"),\n",
    "        (\"Madrid\", \"2025\", \"03\", \"marzo\", \"01\", \"07\", \"hotels_madrid_MWC.csv\"),\n",
    "        (\"Barcelona\", \"2025\", \"03\", \"marzo\", \"22\", \"28\", \"hotels_barcelona_after_MWC.csv\"),\n",
    "        (\"Madrid\", \"2025\", \"03\", \"marzo\", \"22\", \"28\", \"hotels_madrid_after_MWC.csv\")\n",
    "    ]\n",
    "\n",
    "    city, year, month, month_text, arrival_day, departure_day, filename = locations[browser_id]\n",
    "    search_and_scrape(browser, city, year, month, month_text, arrival_day, departure_day, filename)\n",
    "if __name__ == \"__main__\":\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        executor.map(scrape_with_browser, range(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS_enviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
